import streamlit as st
import face_recognition
import cv2
import numpy as np
import BD
import bcrypt
from streamlit_webrtc import VideoTransformerBase, webrtc_streamer

# CrÃ©er la base de donnÃ©es au dÃ©marrage
BD.creer_base()

st.title("ğŸ” Authentification avec Reconnaissance Faciale")

choix = st.selectbox("Choisissez une option", ["Inscription", "Connexion", "Connexion faciale"])

if choix == "Inscription":
    username = st.text_input("ğŸ‘¤ Nom d'utilisateur")
    email = st.text_input("âœ‰ï¸ Email")
    password = st.text_input("ğŸ”‘ Mot de passe", type="password")
    
    if st.button("S'inscrire"):
        with st.spinner("â³ VÃ©rification en cours..."):
            hashed_password = bcrypt.hashpw(password.encode('utf-8'), bcrypt.gensalt())
            if BD.ajouter_utilisateur(username, email, hashed_password):
                st.success("âœ… Inscription rÃ©ussie !")
            else:
                st.error("âŒ Cet email est dÃ©jÃ  utilisÃ©. Veuillez en choisir un autre.")

# Section Connexion
elif choix == "Connexion":
    username = st.text_input("ğŸ‘¤ Nom d'utilisateur")
    password = st.text_input("ğŸ”‘ Mot de passe", type="password")

    if st.button("Se connecter"):
        with st.spinner("â³ VÃ©rification en cours..."):
            if BD.verifier_utilisateur(username, password):
                st.success("âœ… Connexion rÃ©ussie !")
            else:
                st.error("âŒ Identifiants incorrects.")

# Section Connexion faciale
elif choix == "Connexion faciale":
    st.header("ğŸ“¸ Reconnaissance Faciale en Temps RÃ©el")
    st.write("ğŸ” Regardez la camÃ©ra et laissez lâ€™IA vous identifier")

    class FaceIDTransformer(VideoTransformerBase):
        def recv(self, frame):
            img = frame.to_ndarray(format="bgr24")

            alpha, beta = 1.8, 50
            img = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)

            kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])
            img = cv2.filter2D(img, -1, kernel)

            frame_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            face_locations = face_recognition.face_locations(frame_rgb)
            face_encodings = face_recognition.face_encodings(frame_rgb, face_locations)

            if face_encodings: 
                noms, signatures = BD.charger_visages()
                if signatures:
                    distances = face_recognition.face_distance(signatures, face_encodings[0])
                    if distances.any():
                        min_index = np.argmin(distances)
                        seuil = 0.6
                        if distances[min_index] < seuil:
                            st.success(f"âœ… Bienvenue {noms[min_index]} !")
                        else:
                            st.error("âŒ Visage non reconnu. Essayez un meilleur Ã©clairage.")
                    else:
                        st.error("âŒ Aucun visage enregistrÃ© dans la base de donnÃ©es.")
                else:
                    st.error("âŒ La base de donnÃ©es est vide. Enregistrez des visages.")
            else:
                st.warning("âš ï¸ Aucun visage dÃ©tectÃ©. Ajustez la luminositÃ© ou lâ€™angle de vue.")

            return img

    # Lancer la capture vidÃ©o avec WebRTC
    webrtc_streamer(key="facial-recognition", video_processor_factory=FaceIDTransformer)

st.divider()
st.write("ğŸ”’ **SÃ©curisez vos donnÃ©es avec une authentification robuste !**")